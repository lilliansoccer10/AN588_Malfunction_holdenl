---
title: "What's Your Malfunction?"
author: "Lillian Holden"
date: "Final Homework Due November 1 by 5 PM"
output: rmdformats::readthedown
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Five Challenges
1. I found the creation of the function extremely challenging. I was unable to figure out where to start until I went to office hours and professor Schmitt told me about the option to type in the name of a desired test with no additional factors and it will ouput the code used to create it. I used some of this code and altered it to fit the parameters that were required for this assignment. 
2. I had a hard time plotting the line of best fit's model equation onto the graphs. Professor Schmitt directed me to use the annotate() function. I used "?annotate" to find an example of how this function was used and it ended up working for me!
3. I was unable to figure out how to plot the prediction lines within the plots in part two of the assignment. With the help from peer commentary and module 12, I was able to figure it out, which made me extremely happy. 
4. I had issues with creating a warning if the following parameters were not met: 
5. Overall, this assignment was very challenging, and I spent numerous hours working on it trying to work through it. I found that module 12 was very helpful as well as speaking with professor Schmitt at his office hours and booked meetings. I also believe that the assignment will be extremely useful in the future especially for times where we need to create our own function with set parameters to express data how we want it to be expressed.


## Part 1

### Create Two Data Sets with Normal Distribution
```{r}
set.seed(1)
data.frame <- rnorm(50,5,1)
additional.data.frame <- rnorm(50,6,1)
```

### Create the Function


```{r}
z.prop.test <- function (p1, p2 = NULL, alternative = "two.sided", p0, n1, 
   n2 = NULL, conf.level = 0.95) 
{ 
    #Establish Variables for the Alternative Hypothesis That Will be Tested
    choices <- c("two.sided", "greater", "less")
    alt <- pmatch(alternative, choices)
    alternative <- choices[alt]
    

    if (!is.null(p2)) {
        dname <- paste(deparse(substitute(p1)), "and", paste(deparse(substitute(p2))))
    }
  
    else {
        dname <- deparse(substitute(p1))
    }
  
#Finding the Mean of p1
    mp1 <- mean(p1) #name the mean of p1 as mp1
    estimate <- mp1 #estimate the mean of p1 aka mp1
#Perform a One Sample Z Test if p2 is null
    if (is.null(p2)) {
        stderr <- n1/sqrt(mp1)
        zobs <- (mp1 - p0)/stderr
        method <- c("One-sample z-Test")
        names(estimate) <- c("mean of p1")
    }
#Perform a One Sample Z Test if n2 is null
       if (is.null(n2)) {
        stderr <- n1/sqrt(mp1)
        zobs <- (mp1 - p0)/stderr
        method <- c("One-sample z-Test")
        names(estimate) <- c("mean of p1")
    }
    else {
#Perform a Two Sample Z Test if p2 and n2 have values
        mp2 <- mean(p2) #name the mean of p2 as mp2
        method <- c("Two-sample z-Test")
        estimate <- c(mp1, mp2) #estimate the means of p1 and p2
        names(estimate) <- c("mean of p1", "mean of p2")
        stderr <- sqrt(((n1^2)/mp1) + ((n2^2)/mp2))
        zobs <- (mp1 - mp2 - p0)/stderr
    }
    if (alternative == "less") {
        pval <- pnorm(zobs)
        cint <- c(NA, zobs * stderr + qnorm(conf.level) * stderr)
    }
    else if (alternative == "greater") {
        pval <- 1 - pnorm(zobs)
        cint <- c(zobs * stderr - qnorm(conf.level) * stderr, 
            NA)
    }
    else {
        pval <- 2 * pnorm(-abs(zobs))
        alpha <- 1 - conf.level
        cint <- c(zobs * stderr - qnorm((1 - alpha/2)) * stderr, 
            zobs * stderr + qnorm((1 - alpha/2)) * stderr)
    }
    
    cint <- cint + p0
    names(zobs) <- "z"
    if (!is.null(p2)) 
        names(p0) <- "difference in means"
     if (!is.null(p1)) 
        names(p0) <- "difference in means"
  
    else names(p0) <- "mean"
    attr(cint, "conf.level") <- conf.level
#Use the list() function, so that each variable is expressed once the function is run
    rval <- list(statistic = zobs, p.value = pval, conf.int = cint, 
        estimate = estimate, null.value = p0, alternative = alternative, 
        method = method, data.name = dname)
    attr(rval, "class") <- "htest"
    return(rval) #Displays the list that was described
}
```

### Test to See if The Function Works with Multiple Scenerios
```{r}
#Testing the function if p2 and n2 = NULL
z.prop.test(data.frame, additional.data.frame, alternative = "two.sided", p0 = 0, n1 = 2, n2 = NULL, conf.level = 0.95) 
```

```{r}
#Testing the function if p2 = NULL
z.prop.test(data.frame, p2=additional.data.frame, alternative = "two.sided", p0 = 0, n1 = 2, n2 = NULL, conf.level = 0.95) 
```

```{r}
#Testing the function if all information included
z.prop.test(data.frame, p2=additional.data.frame, alternative = "two.sided", p0 = 0, n1 = 2, n2 = 3, conf.level = 0.95) 
```

## Part 2

### Use library() to access the following packages: 
```{r message=FALSE, warning=FALSE}
library(curl)
library(ggplot2)
library(tidyverse)
```

### Import the Data Set
```{r}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall23/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE) #Assign D as the vector for the data set
head(d)
```

#### Call Information Required to Plot the Fitted Line - Determine the Intercept(B0) and Slope (B1)
```{r}
mI <- lm(MaxLongevity_m ~ Brain_Size_Species_Mean, data = d)
summary(mI)
mII <-  lm(log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean), data = d)
summary(mII)
```
### Add A Fitted Line to the Scatterplots Using ggplot2 
```{r warning=FALSE}
par(mfrow = c(1, 2))
g <- ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m))
g <- g + geom_point()
g <- g + geom_smooth(method = "lm", formula = y ~ x)
g + annotate("text", x = 150, y = 800, label = "y=1.2180x + 248.9523")
h <- ggplot(data = d, aes(x = log(Brain_Size_Species_Mean), y = log(MaxLongevity_m)))
h <- h + geom_point()
h <- h + geom_smooth(method = "lm", formula = y ~ x)
h + annotate("text", x = 2, y = 6.5, label = "y=0.23415x +  4.87895")
```


### Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. Also, find a 90 percent CI for the slope (β1) parameter.

- The estimate of the slope B1 for MaxLongevity_m ~ Brain_Size_Species_Mean is 1.2180. When B1 equals 0, y is equal to  248.9523. When B1 does not equal zero, it is the expected change in units of y for every 1 unit of change in x.

- The estimate of the slope B1 for log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean) is 0.23415. When B1 equals 0, y is equal to
4.87895. When B1 does not equal zero, it is the expected change in units of y for every 1 unit of change in x.

### Find a 90% Confidence Interval Based on Each B1(m) Parameter
```{r}
ciI <- confint(mI, level = 0.90)  
ciI
ciII <- confint(mII, level = 0.90)  
ciII
```
### Making a Prediction Based on Each B1(m) Parameter and 90% CI
```{r}
predI <- predict(mI, level = 0.90) 
head (predI)
#Prediction For the Log
predII <- predict(mII, level = 0.90) 
head(predII)
```
### Adding 90% CI Lines and Prediction Lines into A Plot
```{r}
v <-  seq(from = 0, to = 500, by = 10) 
m <- lm(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)
ci <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "confidence", level = 0.90) 
pi <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "prediction", level = 0.90) 
plot(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)
lines(x = v, y = ci[, 1], col = "black") 
lines(x = v, y = ci[, 2], col = "blue")
lines(x = v, y = ci[, 3], col = "blue")
lines(x = v, y = pi[, 2], col = "red")
lines(x = v, y = pi[, 3], col = "red")
legend(350, 300, legend=c("Line of Best Fit", "Confidence", "Prediction"), fill = c("black", "blue","red")) 
```

```{r}
v <-  seq(from = 0, to = 10, by = 1)
Longevity <- log(d$MaxLongevity_m)
Brainsize <- log (d$Brain_Size_Species_Mean)
m <- lm(Longevity ~ Brainsize)
ci <- predict(m, newdata = data.frame(Brainsize = v), interval = "confidence", level = 0.95)
pi <- predict(m, newdata = data.frame(Brainsize = v), interval = "prediction", level = 0.95)
plot(data = d, log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean))
lines(x = v, y = ci[, 1], col = "black")
lines(x = v, y = ci[, 2], col = "blue")
lines(x = v, y = ci[, 3], col = "blue")
lines(x = v, y = pi[, 2], col = "red")
lines(x = v, y = pi[, 3], col = "red")
legend(4.5, 5.25, legend=c("Line of Best Fit", "Confidence", "Prediction"), fill = c("black", "blue","red"))
```

### Making a Prediction if the Brain Weight is 800gm
```{r}
predI <- predict(mI, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "confidence",
    level = 0.90) 
predI
#Prediction For the Log
predII <- predict(mII, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "confidence",
    level = 0.90) 
predII
```

#### I do trust the model to make that prediction because the fit was ~1223 with a 90% CI. The point is predicted to be between ~1089 and ~1357. When 800 is typed into the model equation alone y=1.2180x + 248.9523, it gets ~1223. Also if you type in the log(800) into the log model equation y=0.23415x +  4.87895, you get 6.44152. The point is predicted again with a 90% CI and is found somewhere between ~6.348235 and ~6.540065. I trust both the models to make the correct predictions, especially when there is a 90% CI in the prediction equation. 


